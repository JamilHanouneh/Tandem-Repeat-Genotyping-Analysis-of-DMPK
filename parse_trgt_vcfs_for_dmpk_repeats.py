"""
================================================================================
TANDEM REPEAT GENOTYPING: DMPK CTG EXPANSION ANALYSIS FOR MYOTONIC DYSTROPHY
================================================================================

PURPOSE:
This script analyzes CTG (cytosine-thymine-guanine) trinucleotide repeat 
expansions in the DMPK (Dystrophia Myotonica-Protein Kinase) gene from VCF 
files generated by the Tandem Repeat Genotyping Tool (TRGT). DMPK expansions 
cause Myotonic Dystrophy Type 1 (DM1), a neuromuscular disorder characterized 
by progressive muscle weakness, myotonia, and multi-systemic involvement.

CLINICAL CONTEXT:
- Normal DMPK alleles: 5-35 CTG repeats
- Pre-mutation/gray zone: 35-49 repeats
- Pathogenic threshold: ≥50 CTG repeats (disease-causing)
- Large expansions (>1000 repeats): associated with congenital DM1
- Repeat length correlates with disease severity and age of onset

WORKFLOW OVERVIEW:
1. VCF FILE DISCOVERY & PARSING
   - Scans specified directory for TRGT-generated VCF files
   - Each VCF file corresponds to one biological sample
   - Extracts sample identifiers from filenames

2. DMPK-SPECIFIC DATA EXTRACTION
   - Filters variants to retain only DMPK gene records
   - Extracts genotype call information (allele-specific data)
   - Retrieves TRID (Tandem Repeat ID) from VCF INFO field

3. REPEAT LENGTH PARSING
   - Extracts AL (Allele Length) field containing repeat sizes
   - Handles both list and comma-separated string formats
   - Parses MOTIFS field to identify repeat sequence composition

4. DATA STRUCTURING
   - Organizes extracted data into tabular format
   - Creates one row per allele (diploid samples have two alleles)
   - Stores sample ID, gene name, repeat length, motif, and allele label

5. PATHOGENICITY CLASSIFICATION & VISUALIZATION
   - Generates bar plot showing repeat lengths for each sample/allele
   - Marks pathogenic threshold (>50 repeats) with horizontal red line
   - Annotates bars with exact repeat counts for quantitative assessment

6. MOTIF INTERRUPTION ANALYSIS
   - Detects sequence interruptions within CTG repeat tracts
   - Interruptions (e.g., CCG, CTC, CAG variants) stabilize expansions
   - Interrupted repeats are associated with milder phenotypes and later onset
   - Identifies potential novel variants with heterogeneous motif structure

BIOLOGICAL SIGNIFICANCE:
- Pure CTG repeats are highly unstable and expand across generations
- Interrupted repeats (variant repeats) act as genetic modifiers
- No congenital DM1 cases reported with interrupted expansions
- Interruptions reduce somatic mosaicism and slow disease progression

INPUTS:
- Directory containing TRGT-generated VCF files (.vcf)
- VCF files must contain DMPK gene tandem repeat genotype data
- Expected format: TRGT output from PacBio HiFi long-read sequencing

OUTPUTS:
- Bar plot: DMPK repeat lengths per sample with pathogenic threshold
- Console output: Motif interruption analysis results
- Visual annotations: Repeat counts labeled on bars for clarity

ERROR HANDLING:
- Gracefully handles missing VCF directory
- Catches and reports VCF parsing exceptions
- Validates genotype call data before extraction
- Provides user guidance if no DMPK data found

DATA SOURCE:
Coriell sample dataset from PacBio Public Dataset repository
(TRGT analysis of PureTargetRE benchmark samples)

KEY CLINICAL INTERPRETATION:
- Alleles <35 repeats: Normal, no disease risk
- Alleles 35-49 repeats: Unclear significance, monitor
- Alleles ≥50 repeats: Pathogenic, confirm DM1 diagnosis
- Alleles >100 repeats: Classical DM1 presentation likely
- Alleles >1000 repeats: Risk of severe/congenital form

DEPENDENCIES:
os, pandas, matplotlib, vcfpy
================================================================================
"""

import os  # Module import - Access file system operations
import pandas as pd  # Module import - Enable tabular data manipulation
import matplotlib.pyplot as plt  # Module import - Create visualizations
import vcfpy as vcf  # Module import - Parse VCF genomic files


# ========== PIPELINE STAGE 1: VCF File Discovery ==========

vcf_dir = r"C:\Users\jamel\Desktop\PhD Position in Translational Neurogenetics at TUM School of Medicine and Health & MGZ, Munich – September 10, 2025\1 - Tandem Repeat Genotyping Pipeline Analysis of DMPK Expansions\Dataset\TRGT-VCF_files"  # Path assignment - Define VCF file directory location
repeat_data = []  # List initialization - Create container for parsed repeat records

if os.path.exists(vcf_dir):  # Directory validation - Check path existence before processing
    for vcf_file in os.listdir(vcf_dir):  # Directory iteration - Loop through all files in folder
        if not vcf_file.endswith(".vcf"):  # File extension filtering - Skip non-VCF files
            continue
        sample = vcf_file.split(".")[0]  # String splitting - Extract sample identifier from filename
        vcf_path = os.path.join(vcf_dir, vcf_file)  # Path joining - Construct full file path
        
        try:  # Exception handling - Catch parsing errors gracefully
            reader = vcf.Reader.from_path(vcf_path)  # VCF parsing - Open and read genomic variant file
            
            
            # ========== PIPELINE STAGE 2: DMPK-Specific Data Extraction ==========
            
            for record in reader:  # Record iteration - Process each variant in VCF
                print(record.INFO.get("TRID", "Unknown") == "DMPK")  # Boolean evaluation - Check if variant is DMPK gene
                trid = record.INFO.get("TRID", "Unknown")  # Dictionary access - Extract gene identifier from INFO field
                if trid != "DMPK":  # Conditional filtering - Skip non-DMPK variants
                    continue
                if not record.calls:  # Genotype validation - Skip records without call data
                    continue
                call = record.calls[0]  # Index access - Extract first genotype call
                print(record.calls[0])  # Console output - Display call data for debugging
                
                
                # ========== PIPELINE STAGE 3: Repeat Length Parsing ==========
                
                lengths = call.data.get("AL") or [0]  # Attribute extraction with default - Get allele lengths
                print(lengths)  # Console output - Display raw length data
                if not isinstance(lengths, (list, tuple)):  # Type checking - Verify data structure
                    lengths = [int(x) for x in str(lengths).split(",") if x]  # String parsing & list comprehension - Convert comma-separated string to integers
                else:
                    lengths = [int(x) for x in lengths]  # Type casting - Convert list elements to integers
                print(lengths)  # Console output - Display parsed lengths
                
                motifs = record.INFO.get("MOTIFS") or ["Unknown"]  # INFO field extraction with default - Get repeat motif sequences
                if isinstance(motifs, str):  # Type checking - Handle string motif format
                    motifs = [motifs]  # List wrapping - Standardize motif format
                motif = motifs[0]  # Index access - Extract first motif
                print(motif)  # Console output - Display motif sequence
                
                
                # ========== PIPELINE STAGE 4: Data Structuring ==========
                
                for idx, allele_length in enumerate(lengths):  # Enumeration iteration - Process each allele with index
                    repeat_data.append(  # List append - Add structured record to dataset
                        {
                            "Sample": sample,  # Key-value assignment - Store sample identifier
                            "Gene": trid,  # Key-value assignment - Store gene name
                            "Length": allele_length,  # Key-value assignment - Store repeat length
                            "Motif": motif,  # Key-value assignment - Store motif sequence
                            "Allele": f"Allele {idx}",  # F-string formatting - Create allele label
                        }
                    )
            
            reader.close()  # Resource cleanup - Close file handle
        
        except Exception as e:  # Exception catching - Handle parsing errors
            print(f"Error parsing {vcf_file}: {e}")  # F-string output - Report error with filename

else:
    print("VCF directory not found - check path or ensure TRGT-VCF_files exists.")  # Error message - Alert user to missing directory

vcf_df = pd.DataFrame(repeat_data)  # DataFrame construction - Convert list of dictionaries to tabular format


# ========== PIPELINE STAGE 6: Pathogenicity Classification and Visualization ==========

if not vcf_df.empty:  # DataFrame validation - Check for data before plotting
    plt.figure(figsize=(10, 6))  # Figure initialization - Set plot dimensions
    bars = plt.bar(vcf_df["Sample"] + "_" + vcf_df["Allele"], vcf_df["Length"], color="salmon")  # Bar plot with string concatenation - Visualize repeat lengths per allele
    plt.axhline(y=50, color="red", linestyle="--", label="Pathogenic Threshold (>50 repeats)")  # Horizontal reference line - Mark clinical significance cutoff
    plt.xlabel("Sample and Allele")  # Axis labeling - Describe x-axis
    plt.ylabel("DMPK Repeat Length (bp)")  # Axis labeling - Describe y-axis
    plt.title("DMPK Repeat Expansions in Coriell Samples")  # Plot titling - Describe visualization
    plt.legend()  # Legend display - Show threshold annotation
    plt.xticks(rotation=45, ha="right")  # Axis formatting - Rotate labels for readability
    plt.tight_layout()  # Layout optimization - Prevent label cutoff
    
    for bar in bars:  # Bar iteration - Process each bar for annotation
        yval = bar.get_height()  # Attribute access - Get bar height value
        plt.text(bar.get_x() + bar.get_width() / 2, yval + 20, int(yval), ha="center", va="bottom")  # Text annotation - Label bar with numeric value
    
    plt.show()  # Plot rendering - Display figure

else:
    print(  # Multi-line string output - Provide user guidance
        "No DMPK data found in VCFs - check files or download TRGT VCFs from "
        "https://downloads.pacbcloud.com/public/dataset/PureTargetRE/Coriell/PBMM2-BAM-Input-For-IGV-And-TRGT/."
    )


# ========== PIPELINE STAGE 5: Motif Interruption Analysis ==========

if not vcf_df.empty:  # DataFrame validation - Check for data before analysis
    vcf_df["Interrupted"] = vcf_df["Motif"].apply(  # Column creation with lambda - Add interruption classification
        lambda m: "Yes (Potential Novel Variant)" if len(set(m)) > 1 else "No"  # Set uniqueness test - Detect motif heterogeneity
    )
    print("\nInterruptions in DMPK motifs (mimicking novel patterns):")  # Console output - Print section header
    print(vcf_df[["Sample", "Allele", "Motif", "Interrupted"]])  # DataFrame subsetting & display - Show interruption results
